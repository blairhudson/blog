<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Optimising hyper-parameters efficiently with Scikit-Optimize | Data Everythingist</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="http://blairhudson.github.io/blog/posts/optimising-hyper-parameters-efficiently-with-scikit-optimize/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Blair Hudson">
<link rel="prev" href="../using-jupyter-notebooks-with-anaconda/" title="Using Jupyter notebooks with Anaconda" type="text/html">
<meta property="og:site_name" content="Data Everythingist">
<meta property="og:title" content="Optimising hyper-parameters efficiently with Scikit-Optimize">
<meta property="og:url" content="http://blairhudson.github.io/blog/posts/optimising-hyper-parameters-efficiently-with-scikit-optimize/">
<meta property="og:description" content="One of the most well-known techniques for experimenting with various model configurations is Grid Search.
With grid search, you specify a discrete search space (a parameter grid) of all of the paramet">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2017-09-13T21:12:52+10:00">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md navbar-dark bg-dark static-top mb-4"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="http://blairhudson.github.io/blog/">

            <span id="blog-title">Data Everythingist</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="../../archive.html" class="nav-link">Archive</a>
                </li>
<li class="nav-item">
<a href="../../rss.xml" class="nav-link">RSS</a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right">
<li class="nav-item">
    <a href="index.ipynb" id="sourcelink" class="nav-link">Source</a>
    </li>

                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Optimising hyper-parameters efficiently with Scikit-Optimize</a></h1>

        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                    Blair Hudson
            </span></p>
            <p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2017-09-13T21:12:52+10:00" itemprop="datePublished" title="2017-09-13 21:12">2017-09-13 21:12</time></a></p>
            
        <p class="sourceline"><a href="index.ipynb" class="sourcelink">Source</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>One of the most well-known techniques for experimenting with various model configurations is <em>Grid Search</em>.</p>
<p>With grid search, you specify a discrete search space (a parameter grid) of all of the parameter values you would like to test. The search permutes through the grid, testing various combinations until all are exhausted. Basic a specified performance metric (e.g. error), you can select the best parameter combination for your model.</p>
<p>What's wrong with this?</p>
<p>If you have a large parameter grid, this doesn't work too well:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'param_a'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
    <span class="s1">'param_b'</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
    <span class="s1">'param_c'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">num_searches</span><span class="p">(</span><span class="n">param_grid</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">param_grid</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
    
<span class="n">num_searches</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[1]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>27</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And maybe we want to search over four possible values instead for <code>param_a</code>, and add two more new parameters:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'param_a'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
    <span class="s1">'param_b'</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
    <span class="s1">'param_c'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
    <span class="s1">'param_d'</span><span class="p">:</span> <span class="p">[</span><span class="s2">"a"</span><span class="p">,</span> <span class="s2">"b"</span><span class="p">],</span>
    <span class="s1">'param_e'</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">num_searches</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[2]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>216</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see from the first grid, there's already 27 combinations to try. Then this jumps to 216 for our larger grid. Depending on the complexity of the model and the amount of data to process, this can very easily become infeasible.</p>
<p>There are a few approaches to solving this, including:</p>
<ul>
<li>breaking down the search into multiple smaller steps (such as searching <code>param_a</code> and <code>param_b</code> first, with defaults for the others, then using the best values to search the remaining parameters - this can be tricky in practice)</li>
<li>searching the parameter space <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html">at random</a> (which has an additional benefit of discovering better parameter values when random samples are drawn frmo a continuous range)</li>
</ul>
<p>While Scikit-Learn doesn't provide many more options, some <a href="https://github.com/scikit-optimize/scikit-optimize/blob/master/AUTHORS.md">clever people</a> have developed a drop-in replacement for Scikit-Learn's <code>GridSearchCV</code> and <code>RandomizedSearchCV</code> called <code>BayesSearchCV</code> in a package called <em>Scikit-Optimize</em>.</p>
<p>Let's install Scikit-Optimize and implement <code>BayesSearchCV</code> with a simple example!</p>
<h3 id="Installing-Scikit-Optimize">Installing Scikit-Optimize<a class="anchor-link" href="#Installing-Scikit-Optimize">¶</a>
</h3>
<p>Assuming you already have already <a href="../using-jupyter-notebooks-with-anaconda/">installed Anaconda and Jupyter</a>, you will need to do the following:</p>
<ul>
<li><code>pip install scikit-optimize</code></li>
</ul>
<p>If you have trouble installing, you may first need to run the following to install one of Scikit-Optmize's dependencies:</p>
<ul>
<li><code>pip install scikit-garden</code></li>
</ul>
<h3 id="Implementing-BayesSearchCV">Implementing <code>BayesSearchCV</code><a class="anchor-link" href="#Implementing-BayesSearchCV">¶</a>
</h3>
<p>Here's an example implementation using a sample dataset and <a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">Logistic Regression</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">skopt</span> <span class="k">import</span> <span class="n">BayesSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>

<span class="c1"># prep some sample data</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span>

<span class="c1"># we're using a logistic regression model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># this is our parameter grid</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'solver'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'liblinear'</span><span class="p">,</span> <span class="s1">'saga'</span><span class="p">],</span>  
    <span class="s1">'penalty'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'l1'</span><span class="p">,</span><span class="s1">'l2'</span><span class="p">],</span>
    <span class="s1">'tol'</span><span class="p">:</span> <span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="s1">'log-uniform'</span><span class="p">),</span>
    <span class="s1">'C'</span><span class="p">:</span> <span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="s1">'log-uniform'</span><span class="p">),</span>
    <span class="s1">'fit_intercept'</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># set up our optimiser to find the best params in 30 searches</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">BayesSearchCV</span><span class="p">(</span>
    <span class="n">clf</span><span class="p">,</span>
    <span class="n">param_grid</span><span class="p">,</span>
    <span class="n">n_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>

<span class="n">opt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.
  FutureWarning)
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=True, tol=0.000382254605256, C=0.000825787721576, solver=saga, penalty=l2 
[CV]  fit_intercept=True, tol=0.000382254605256, C=0.000825787721576, solver=saga, penalty=l2, total=   0.1s
[CV] fit_intercept=True, tol=0.000382254605256, C=0.000825787721576, solver=saga, penalty=l2 
[CV]  fit_intercept=True, tol=0.000382254605256, C=0.000825787721576, solver=saga, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=0.000382254605256, C=0.000825787721576, solver=saga, penalty=l2 
[CV]  fit_intercept=True, tol=0.000382254605256, C=0.000825787721576, solver=saga, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=True, tol=0.000555351500381, C=0.243756153601, solver=saga, penalty=l2 
[CV]  fit_intercept=True, tol=0.000555351500381, C=0.243756153601, solver=saga, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=0.000555351500381, C=0.243756153601, solver=saga, penalty=l2 
[CV]  fit_intercept=True, tol=0.000555351500381, C=0.243756153601, solver=saga, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=0.000555351500381, C=0.243756153601, solver=saga, penalty=l2 
[CV]  fit_intercept=True, tol=0.000555351500381, C=0.243756153601, solver=saga, penalty=l2, total=   0.0s
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=True, tol=0.00021856668705, C=0.000379398151643, solver=liblinear, penalty=l1 
[CV]  fit_intercept=True, tol=0.00021856668705, C=0.000379398151643, solver=liblinear, penalty=l1, total=   0.0s
[CV] fit_intercept=True, tol=0.00021856668705, C=0.000379398151643, solver=liblinear, penalty=l1 
[CV]  fit_intercept=True, tol=0.00021856668705, C=0.000379398151643, solver=liblinear, penalty=l1, total=   0.0s
[CV] fit_intercept=True, tol=0.00021856668705, C=0.000379398151643, solver=liblinear, penalty=l1 
[CV]  fit_intercept=True, tol=0.00021856668705, C=0.000379398151643, solver=liblinear, penalty=l1, total=   0.0s
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=True, tol=0.000102890478113, C=0.00840588302113, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=0.000102890478113, C=0.00840588302113, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=0.000102890478113, C=0.00840588302113, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=0.000102890478113, C=0.00840588302113, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=0.000102890478113, C=0.00840588302113, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=0.000102890478113, C=0.00840588302113, solver=liblinear, penalty=l2, total=   0.0s
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=True, tol=0.000920403419315, C=0.00194382983221, solver=saga, penalty=l1 
[CV]  fit_intercept=True, tol=0.000920403419315, C=0.00194382983221, solver=saga, penalty=l1, total=   0.0s
[CV] fit_intercept=True, tol=0.000920403419315, C=0.00194382983221, solver=saga, penalty=l1 
[CV]  fit_intercept=True, tol=0.000920403419315, C=0.00194382983221, solver=saga, penalty=l1, total=   0.0s
[CV] fit_intercept=True, tol=0.000920403419315, C=0.00194382983221, solver=saga, penalty=l1 
[CV]  fit_intercept=True, tol=0.000920403419315, C=0.00194382983221, solver=saga, penalty=l1, total=   0.0s
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=True, tol=3.94082520634e-05, C=0.000130052012491, solver=liblinear, penalty=l1 
[CV]  fit_intercept=True, tol=3.94082520634e-05, C=0.000130052012491, solver=liblinear, penalty=l1, total=   0.0s
[CV] fit_intercept=True, tol=3.94082520634e-05, C=0.000130052012491, solver=liblinear, penalty=l1 
[CV]  fit_intercept=True, tol=3.94082520634e-05, C=0.000130052012491, solver=liblinear, penalty=l1, total=   0.0s
[CV] fit_intercept=True, tol=3.94082520634e-05, C=0.000130052012491, solver=liblinear, penalty=l1 
[CV]  fit_intercept=True, tol=3.94082520634e-05, C=0.000130052012491, solver=liblinear, penalty=l1, total=   0.0s
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=False, tol=0.000349866443736, C=0.704155417474, solver=saga, penalty=l2 
[CV]  fit_intercept=False, tol=0.000349866443736, C=0.704155417474, solver=saga, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=0.000349866443736, C=0.704155417474, solver=saga, penalty=l2 
[CV]  fit_intercept=False, tol=0.000349866443736, C=0.704155417474, solver=saga, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=0.000349866443736, C=0.704155417474, solver=saga, penalty=l2 
[CV]  fit_intercept=False, tol=0.000349866443736, C=0.704155417474, solver=saga, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=False, tol=0.000550604891749, C=1.95909841601, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=0.000550604891749, C=1.95909841601, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=0.000550604891749, C=1.95909841601, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=0.000550604891749, C=1.95909841601, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=0.000550604891749, C=1.95909841601, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=0.000550604891749, C=1.95909841601, solver=liblinear, penalty=l2, total=   0.0s
Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=True, tol=2.57731741777e-05, C=0.0933134709093, solver=saga, penalty=l1 
[CV]  fit_intercept=True, tol=2.57731741777e-05, C=0.0933134709093, solver=saga, penalty=l1, total=   0.0s
[CV] fit_intercept=True, tol=2.57731741777e-05, C=0.0933134709093, solver=saga, penalty=l1 
[CV]  fit_intercept=True, tol=2.57731741777e-05, C=0.0933134709093, solver=saga, penalty=l1, total=   0.0s
[CV] fit_intercept=True, tol=2.57731741777e-05, C=0.0933134709093, solver=saga, penalty=l1 
[CV]  fit_intercept=True, tol=2.57731741777e-05, C=0.0933134709093, solver=saga, penalty=l1, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=False, tol=5.06278923847e-05, C=5.86409384188, solver=saga, penalty=l2 
[CV]  fit_intercept=False, tol=5.06278923847e-05, C=5.86409384188, solver=saga, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=5.06278923847e-05, C=5.86409384188, solver=saga, penalty=l2 
[CV]  fit_intercept=False, tol=5.06278923847e-05, C=5.86409384188, solver=saga, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=5.06278923847e-05, C=5.86409384188, solver=saga, penalty=l2 
[CV]  fit_intercept=False, tol=5.06278923847e-05, C=5.86409384188, solver=saga, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=False, tol=0.001, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=0.001, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=0.001, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=0.001, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=0.001, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=0.001, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=True, tol=0.001, C=0.00171621716873, solver=liblinear, penalty=l1 
[CV]  fit_intercept=True, tol=0.001, C=0.00171621716873, solver=liblinear, penalty=l1, total=   0.0s
[CV] fit_intercept=True, tol=0.001, C=0.00171621716873, solver=liblinear, penalty=l1 
[CV]  fit_intercept=True, tol=0.001, C=0.00171621716873, solver=liblinear, penalty=l1, total=   0.0s
[CV] fit_intercept=True, tol=0.001, C=0.00171621716873, solver=liblinear, penalty=l1 
[CV]  fit_intercept=True, tol=0.001, C=0.00171621716873, solver=liblinear, penalty=l1, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=False, tol=0.000742149491069, C=4.65040156797, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=0.000742149491069, C=4.65040156797, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=0.000742149491069, C=4.65040156797, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=0.000742149491069, C=4.65040156797, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=0.000742149491069, C=4.65040156797, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=0.000742149491069, C=4.65040156797, solver=liblinear, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=False, tol=0.000289050608323, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=0.000289050608323, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=0.000289050608323, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=0.000289050608323, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=0.000289050608323, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=0.000289050608323, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=False, tol=1e-05, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=1e-05, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=1e-05, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=1e-05, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=1e-05, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=1e-05, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=False, tol=0.000157629057632, C=100.0, solver=saga, penalty=l1 
[CV]  fit_intercept=False, tol=0.000157629057632, C=100.0, solver=saga, penalty=l1, total=   0.0s
[CV] fit_intercept=False, tol=0.000157629057632, C=100.0, solver=saga, penalty=l1 
[CV]  fit_intercept=False, tol=0.000157629057632, C=100.0, solver=saga, penalty=l1, total=   0.0s
[CV] fit_intercept=False, tol=0.000157629057632, C=100.0, solver=saga, penalty=l1 
[CV]  fit_intercept=False, tol=0.000157629057632, C=100.0, solver=saga, penalty=l1, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=True, tol=1e-05, C=1e-05, solver=saga, penalty=l2 .
[CV]  fit_intercept=True, tol=1e-05, C=1e-05, solver=saga, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=1e-05, C=1e-05, solver=saga, penalty=l2 .
[CV]  fit_intercept=True, tol=1e-05, C=1e-05, solver=saga, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=1e-05, C=1e-05, solver=saga, penalty=l2 .
[CV]  fit_intercept=True, tol=1e-05, C=1e-05, solver=saga, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=False, tol=1e-05, C=100.0, solver=saga, penalty=l1 
[CV]  fit_intercept=False, tol=1e-05, C=100.0, solver=saga, penalty=l1, total=   0.0s
[CV] fit_intercept=False, tol=1e-05, C=100.0, solver=saga, penalty=l1 
[CV]  fit_intercept=False, tol=1e-05, C=100.0, solver=saga, penalty=l1, total=   0.0s
[CV] fit_intercept=False, tol=1e-05, C=100.0, solver=saga, penalty=l1 
[CV]  fit_intercept=False, tol=1e-05, C=100.0, solver=saga, penalty=l1, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=False, tol=9.55256066036e-05, C=0.0267622531962, solver=saga, penalty=l2 
[CV]  fit_intercept=False, tol=9.55256066036e-05, C=0.0267622531962, solver=saga, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=9.55256066036e-05, C=0.0267622531962, solver=saga, penalty=l2 
[CV]  fit_intercept=False, tol=9.55256066036e-05, C=0.0267622531962, solver=saga, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=9.55256066036e-05, C=0.0267622531962, solver=saga, penalty=l2 
[CV]  fit_intercept=False, tol=9.55256066036e-05, C=0.0267622531962, solver=saga, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=False, tol=2.14150718478e-05, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=2.14150718478e-05, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=2.14150718478e-05, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=2.14150718478e-05, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=2.14150718478e-05, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=2.14150718478e-05, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=True, tol=1e-05, C=38.4658080596, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=1e-05, C=38.4658080596, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=1e-05, C=38.4658080596, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=1e-05, C=38.4658080596, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=1e-05, C=38.4658080596, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=1e-05, C=38.4658080596, solver=liblinear, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=False, tol=0.001, C=3.18302458993, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=0.001, C=3.18302458993, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=0.001, C=3.18302458993, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=0.001, C=3.18302458993, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=0.001, C=3.18302458993, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=0.001, C=3.18302458993, solver=liblinear, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=False, tol=1e-05, C=61.9366266622, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=1e-05, C=61.9366266622, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=1e-05, C=61.9366266622, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=1e-05, C=61.9366266622, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=1e-05, C=61.9366266622, solver=liblinear, penalty=l2 
[CV]  fit_intercept=False, tol=1e-05, C=61.9366266622, solver=liblinear, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=True, tol=1.52191042725e-05, C=1e-05, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=1.52191042725e-05, C=1e-05, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=1.52191042725e-05, C=1e-05, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=1.52191042725e-05, C=1e-05, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=1.52191042725e-05, C=1e-05, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=1.52191042725e-05, C=1e-05, solver=liblinear, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=True, tol=5.84228443388e-05, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=5.84228443388e-05, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=5.84228443388e-05, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=5.84228443388e-05, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=5.84228443388e-05, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=5.84228443388e-05, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=False, tol=0.00054754356556, C=0.00366650548222, solver=saga, penalty=l2 
[CV]  fit_intercept=False, tol=0.00054754356556, C=0.00366650548222, solver=saga, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=0.00054754356556, C=0.00366650548222, solver=saga, penalty=l2 
[CV]  fit_intercept=False, tol=0.00054754356556, C=0.00366650548222, solver=saga, penalty=l2, total=   0.0s
[CV] fit_intercept=False, tol=0.00054754356556, C=0.00366650548222, solver=saga, penalty=l2 
[CV]  fit_intercept=False, tol=0.00054754356556, C=0.00366650548222, solver=saga, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=True, tol=1e-05, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=1e-05, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=1e-05, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=1e-05, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=1e-05, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=1e-05, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=True, tol=5.54807277677e-05, C=0.825090969286, solver=saga, penalty=l1 
[CV]  fit_intercept=True, tol=5.54807277677e-05, C=0.825090969286, solver=saga, penalty=l1, total=   0.0s
[CV] fit_intercept=True, tol=5.54807277677e-05, C=0.825090969286, solver=saga, penalty=l1 
[CV]  fit_intercept=True, tol=5.54807277677e-05, C=0.825090969286, solver=saga, penalty=l1, total=   0.0s
[CV] fit_intercept=True, tol=5.54807277677e-05, C=0.825090969286, solver=saga, penalty=l1 
[CV]  fit_intercept=True, tol=5.54807277677e-05, C=0.825090969286, solver=saga, penalty=l1, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished
/Users/blairhudson/anaconda/lib/python3.5/site-packages/skopt/optimizer/optimizer.py:366: UserWarning: The objective has been evaluated at this point before.
  warnings.warn("The objective has been evaluated "
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=True, tol=1e-05, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=1e-05, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=1e-05, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=1e-05, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=1e-05, C=100.0, solver=liblinear, penalty=l2 
[CV]  fit_intercept=True, tol=1e-05, C=100.0, solver=liblinear, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fitting 3 folds for each of 1 candidates, totalling 3 fits
[CV] fit_intercept=True, tol=1e-05, C=63.2457136517, solver=saga, penalty=l2 
[CV]  fit_intercept=True, tol=1e-05, C=63.2457136517, solver=saga, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=1e-05, C=63.2457136517, solver=saga, penalty=l2 
[CV]  fit_intercept=True, tol=1e-05, C=63.2457136517, solver=saga, penalty=l2, total=   0.0s
[CV] fit_intercept=True, tol=1e-05, C=63.2457136517, solver=saga, penalty=l2 
[CV]  fit_intercept=True, tol=1e-05, C=63.2457136517, solver=saga, penalty=l2, total=   0.0s
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
/Users/blairhudson/anaconda/lib/python3.5/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge
  "the coef_ did not converge", ConvergenceWarning)
[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Best params achieve a test score of'</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="s1">':'</span><span class="p">)</span>

<span class="n">opt</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Best params achieve a test score of 0.951048951049 :
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt output_prompt">Out[4]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>{'C': 100.0,
 'fit_intercept': True,
 'penalty': 'l2',
 'solver': 'liblinear',
 'tol': 1.0000000000000001e-05}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By increasing the value of <code>n_iter</code>, you can continue the search to find better parameter combinations. You can also use the optimiser for prediction, by calling <code>.predict()</code> or <code>.predict_proba()</code> for probabilities, or extract and use the best one standalone:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">opt</span><span class="o">.</span><span class="n">best_estimator_</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[5]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=1234, solver='liblinear',
          tol=1.0000000000000001e-05, verbose=0, warm_start=False)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You may also find it useful to re-use the best parameters programatically to define an equivalent model:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">LogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="n">opt</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[6]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear',
          tol=1.0000000000000001e-05, verbose=0, warm_start=False)</pre>
</div>

</div>

</div>
</div>

</div>
    </div>
  </div>

    </div>
    <aside class="postpromonav"><nav><ul class="pager hidden-print">
<li class="previous">
                <a href="../using-jupyter-notebooks-with-anaconda/" rel="prev" title="Using Jupyter notebooks with Anaconda">Previous post</a>
            </li>
        </ul></nav></aside><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha256-SDRP1VVYu+tgAGKhddBSl5+ezofHKZeI+OzxakbIe/Y=" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']]}});
        </script></article><!--End of body content--><footer id="footer">
            Contents © 2017         <a href="http://blairhudson.com">Blair Hudson</a>
            
        </footer>
</div>
</div>


            <script src="../../assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates -->
</body>
</html>
