<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="The personal blog of Blair Hudson, The Data Everythingist">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Data Everythingist (page 1) | Data Everythingist</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">
<link rel="canonical" href="http://blairhudson.github.io/blog/">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]--><link rel="prefetch" href="posts/accessing-jupyter-notebooks-programatically/" type="text/html">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md navbar-dark bg-dark static-top mb-4"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="http://blairhudson.github.io/blog/">

            <span id="blog-title">Data Everythingist</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="archive.html" class="nav-link">Archive</a>
                </li>
<li class="nav-item">
<a href="rss.xml" class="nav-link">RSS</a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        

    


    
<div class="postindex">
    <article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/accessing-jupyter-notebooks-programatically/" class="u-url">Accessing Jupyter notebooks programatically</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Blair Hudson
            </span></p>
            <p class="dateline"><a href="posts/accessing-jupyter-notebooks-programatically/" rel="bookmark"><time class="published dt-published" datetime="2017-09-16T22:12:59+10:00" title="2017-09-16 22:12">2017-09-16 22:12</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You may have seen a previous post where we <a href="posts/introduction-to-classification-using-logistic-regression-with-scikit-learn">created a simple classifier</a> using Scikit-Learn's <code>LogisticRegression</code>.</p>
<p>As we pieced together our model, we structured the code into a class called <code>CustomModel</code>, with two functions: <code>fit</code> and <code>predict</code>.</p>
<p>To start working programatically with the notebook created in that post, you will first need to install the <code>ipynb</code> package:</p>

<pre><code>pip install git+https://github.com/blairhudson/ipynb</code></pre>
<p>(Note: This is actually a fork of an <a href="https://github.com/ipython/ipynb">IPython repo</a>. Unfortunately the master has a bug with parsing tuple-based assignments (e.g. <code>X, y = ...</code>). A <a href="https://github.com/ipython/ipynb/pull/34">pull request</a> has been submitted.)</p>
<p>Now you're ready to go!</p>
<h3 id="Using-the-ipynb-package">Using the ipynb package<a class="anchor-link" href="posts/accessing-jupyter-notebooks-programatically/#Using-the-ipynb-package">¶</a>
</h3>
<p>To simplify things considerably, make sure that you have a copy of <a href="posts/introduction-to-classification-using-logistic-regression-with-scikit-learn/Introduction%20to%20Classification%20using%20Logistic%20Regression%20with%20Scikit-Learn.ipynb">the source</a> in the current working directory, and rename it to <code>model.ipynb</code>.</p>
<p>Now, thanks to the <code>ipynb</code> package you can access the <code>CustomModel</code> class like this:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">ipynb.fs.defs.model</span> <span class="k">import</span> <span class="n">CustomModel</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To prove it, let's generate predictions on the same sample data:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
                                                    <span class="n">train_size</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> 
                                                    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> 
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span> <span class="c1"># more reproducibility</span>

<span class="c1"># load our model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">CustomModel</span><span class="p">()</span>

<span class="c1"># fit our model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># generate some predictions</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[6]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>array([  9.25168417e-01,   9.99922130e-01,   9.53635418e-01,
         9.88416588e-01,   9.97542577e-01,   9.95232506e-01,
         4.60659258e-02,   9.98390194e-01,   6.59002902e-10,
         2.76899836e-06,   8.30718694e-10,   9.63993586e-01,
         9.94157890e-01,   9.50980576e-01,   9.96974859e-01,
         6.97038792e-10,   9.99809391e-01,   9.96431765e-01,
         9.99363563e-01,   8.43800531e-06,   9.95502414e-01,
         7.77576547e-03,   1.12727716e-09,   3.40904102e-17,
         3.68627970e-09,   6.55649762e-01,   3.51723839e-03,
         9.97326888e-01,   9.98785233e-01,   9.97552026e-01,
         9.86350517e-01,   9.98844211e-01,   5.70842717e-04,
         9.87742427e-01,   9.19814189e-01,   9.78443649e-01,
         9.92882821e-01,   1.14676290e-02,   1.48817234e-01,
         9.98733024e-01,   4.13813658e-05,   9.93177003e-01,
         1.72319657e-10,   8.54534408e-01,   8.81187668e-01,
         9.97568264e-01,   9.98086681e-01,   8.32784885e-01,
         4.49929586e-11,   8.89087737e-01,   9.28259947e-01,
         9.91244116e-01,   9.94876558e-01,   1.51106510e-08,
         2.60668778e-01,   9.99597520e-01,   9.98940073e-01,
         9.99968817e-01,   9.91318570e-01,   8.29369844e-03,
         9.93238377e-01,   9.92431535e-01,   9.29775117e-01,
         9.99271713e-01,   9.96474598e-01,   2.41572863e-04,
         1.51376226e-11,   9.97330558e-01,   9.98831771e-01,
         4.79400697e-01,   9.99798779e-01,   3.57307727e-07,
         9.99656809e-01,   7.03641088e-01,   9.98247027e-01,
         9.96093354e-01,   9.99588791e-01,   2.58369708e-08,
         9.98136922e-01,   7.97865310e-03,   9.99065333e-01,
         9.98470351e-01,   9.94581260e-01,   9.29328694e-01,
         1.41996390e-02,   1.43214384e-04,   3.71155631e-05,
         4.45838811e-06,   9.13207438e-01,   8.56295696e-01,
         9.99467328e-01,   9.74324559e-01,   9.99328632e-01,
         2.91312374e-12,   1.00998256e-01,   9.86992421e-01,
         9.97149193e-01,   9.13815924e-01,   9.98807818e-01,
         9.84005486e-01,   3.17865443e-08,   2.30937811e-11,
         9.98036358e-01,   9.99532884e-01,   1.24075526e-03,
         9.98819765e-01,   9.99752279e-01,   8.53677349e-04,
         1.53192255e-01,   9.30832406e-01,   1.49723823e-05,
         5.28688983e-01,   1.48786146e-03,   9.92804571e-51,
         8.86447353e-01,   9.95516043e-01,   9.98554149e-01,
         1.75078944e-03,   9.99922978e-01,   4.67159833e-01,
         9.99825913e-01,   9.57716419e-01,   9.95069689e-01,
         9.98728887e-01,   7.49375338e-14,   9.92513330e-01,
         1.49918676e-02,   1.63977226e-02,   9.95785292e-01,
         9.56124754e-01,   3.53639065e-01,   9.96011137e-01,
         7.27728677e-33,   9.97779030e-01,   7.77872222e-02,
         9.90058068e-01,   9.80367925e-01,   2.92408222e-01,
         9.98164180e-01,   1.67926421e-01,   9.99996297e-01,
         6.35631576e-10,   1.06440027e-01])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Magic ✨</p>

</div>
</div>
</div>
    </div>
  </div>

    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/using-jupyter-notebooks-with-anaconda/" class="u-url">Using Jupyter notebooks with Anaconda</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Blair Hudson
            </span></p>
            <p class="dateline"><a href="posts/using-jupyter-notebooks-with-anaconda/" rel="bookmark"><time class="published dt-published" datetime="2017-09-16T20:08:20+10:00" title="2017-09-16 20:08">2017-09-16 20:08</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Jupyter is a popular data science environment, and Jupyter notebooks (such as <a href="posts/using-jupyter-notebooks-with-anaconda/Using%20Jupyter%20notebooks%20with%20Anaconda.ipynb">the notebook this post</a> was written with) are a great way to create and share great data science with inline documentation (using Markdown syntax).</p>
<p>Jupyter is capable of running kernels in many different programming languages, but in this post we're focussed just on Python.</p>
<h3 id="Installing-Anaconda">Installing Anaconda<a class="anchor-link" href="posts/using-jupyter-notebooks-with-anaconda/#Installing-Anaconda">¶</a>
</h3>
<ol>
<li>Download Anaconda for your operating system from the <a href="https://www.anaconda.com/download">Anaconda website</a>. For best compatibility with modern data science packages, I suggest Python 3.6 version or newer.</li>
<li>Run the downloaded installer and follow the prompts.</li>
</ol>
<h3 id="Launching-Jupyter">Launching Jupyter<a class="anchor-link" href="posts/using-jupyter-notebooks-with-anaconda/#Launching-Jupyter">¶</a>
</h3>
<ol>
<li>Run the following command to launch the Jupyter environment in your current directory:
 <code>jupyter notebook</code>
</li>
<li>By default, this will open the web interface in your default web browser, and by default at <a href="http://localhost:8888/">http://localhost:8888/</a>.</li>
<li>Now you can select an existing <code>.ipynb</code> file from the file navigator to open it, or create a new notebook.</li>
</ol>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">"🚀"</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>🚀
</pre>
</div>
</div>

</div>
</div>

</div>
    </div>
  </div>

    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/introduction-to-classification-using-logistic-regression-with-scikit-learn/" class="u-url">Introduction to Classification using Logistic Regression with Scikit-Learn</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Blair Hudson
            </span></p>
            <p class="dateline"><a href="posts/introduction-to-classification-using-logistic-regression-with-scikit-learn/" rel="bookmark"><time class="published dt-published" datetime="2017-09-16T19:53:46+10:00" title="2017-09-16 19:53">2017-09-16 19:53</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This post, including the source <code>.ipynb</code> notebook file, will be used as a basis for other topics. You can obtain a copy of the source by clicking the <em>Source</em> link at the post of this post.</p>
<p>To keep things simple, we're going to utilise one of the <a href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets">many toy datasets</a> built into Scikit-Learn! (And yes, it is a <a href="https://goo.gl/U2Uwz2">real dataset</a>.)</p>
<p>We're also not going to explain <em>how</em> Scikit-Learn's <code>LogisticRegression</code> is implemented in this post.</p>
<p>To structure our code, we will define our model in two parts:</p>
<ul>
<li>The code we need to fit our model</li>
<li>The code we need to use our fitted model to generate predictions</li>
</ul>
<p>When it comes to model building, these are the two main functional components - so, and for reasons which will be explained in other posts, we're going to build a Python class called <code>CustomModel</code>, with a function for each of these components:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>

<span class="k">class</span> <span class="nc">CustomModel</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>

        <span class="c1"># LogisticRegression implements a number of parameters, you can read about them here:</span>
        <span class="c1"># http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html</span>
        <span class="c1">#</span>
        <span class="c1"># With the exception of `random_state`, each of these are the defaults.</span>
        
        <span class="n">model_params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">'penalty'</span><span class="p">:</span> <span class="s1">'l2'</span><span class="p">,</span>
            <span class="s1">'dual'</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="s1">'tol'</span><span class="p">:</span> <span class="mf">0.0001</span><span class="p">,</span>
            <span class="s1">'C'</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
            <span class="s1">'fit_intercept'</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s1">'intercept_scaling'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s1">'class_weight'</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
            <span class="s1">'random_state'</span><span class="p">:</span> <span class="mi">1234</span><span class="p">,</span>    <span class="c1"># Fixed to 1234 for reproducibility</span>
            <span class="s1">'solver'</span><span class="p">:</span> <span class="s1">'liblinear'</span><span class="p">,</span>
            <span class="s1">'max_iter'</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
            <span class="s1">'multi_class'</span><span class="p">:</span> <span class="s1">'ovr'</span><span class="p">,</span>
            <span class="s1">'verbose'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s1">'warm_start'</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="s1">'n_jobs'</span><span class="p">:</span> <span class="mi">1</span>
        <span class="p">}</span>
    
        <span class="bp">self</span><span class="o">.</span><span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="n">model_params</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="bp">self</span> <span class="c1"># fun fact: returning self enables method chaining i.e. .fit().predict()</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        
        <span class="c1"># We only want to output the positive case (the second column returned by `predict_proba`:</span>
    
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we're ready to use our model!</p>
<p>In the next section we're going to load the sample data discussed above, and divide it into two portions:</p>
<ul>
<li>75% for model fitting</li>
<li>25% for predictions</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
                                                    <span class="n">train_size</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> 
                                                    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> 
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span> <span class="c1"># more reproducibility</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we have everything we need, lets load up our model, fit it with the training data, and generate some predictions:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># load our model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">CustomModel</span><span class="p">()</span>

<span class="c1"># fit our model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># generate some predictions</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[3]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>array([  9.25168417e-01,   9.99922130e-01,   9.53635418e-01,
         9.88416588e-01,   9.97542577e-01,   9.95232506e-01,
         4.60659258e-02,   9.98390194e-01,   6.59002902e-10,
         2.76899836e-06,   8.30718694e-10,   9.63993586e-01,
         9.94157890e-01,   9.50980576e-01,   9.96974859e-01,
         6.97038792e-10,   9.99809391e-01,   9.96431765e-01,
         9.99363563e-01,   8.43800531e-06,   9.95502414e-01,
         7.77576547e-03,   1.12727716e-09,   3.40904102e-17,
         3.68627970e-09,   6.55649762e-01,   3.51723839e-03,
         9.97326888e-01,   9.98785233e-01,   9.97552026e-01,
         9.86350517e-01,   9.98844211e-01,   5.70842717e-04,
         9.87742427e-01,   9.19814189e-01,   9.78443649e-01,
         9.92882821e-01,   1.14676290e-02,   1.48817234e-01,
         9.98733024e-01,   4.13813658e-05,   9.93177003e-01,
         1.72319657e-10,   8.54534408e-01,   8.81187668e-01,
         9.97568264e-01,   9.98086681e-01,   8.32784885e-01,
         4.49929586e-11,   8.89087737e-01,   9.28259947e-01,
         9.91244116e-01,   9.94876558e-01,   1.51106510e-08,
         2.60668778e-01,   9.99597520e-01,   9.98940073e-01,
         9.99968817e-01,   9.91318570e-01,   8.29369844e-03,
         9.93238377e-01,   9.92431535e-01,   9.29775117e-01,
         9.99271713e-01,   9.96474598e-01,   2.41572863e-04,
         1.51376226e-11,   9.97330558e-01,   9.98831771e-01,
         4.79400697e-01,   9.99798779e-01,   3.57307727e-07,
         9.99656809e-01,   7.03641088e-01,   9.98247027e-01,
         9.96093354e-01,   9.99588791e-01,   2.58369708e-08,
         9.98136922e-01,   7.97865310e-03,   9.99065333e-01,
         9.98470351e-01,   9.94581260e-01,   9.29328694e-01,
         1.41996390e-02,   1.43214384e-04,   3.71155631e-05,
         4.45838811e-06,   9.13207438e-01,   8.56295696e-01,
         9.99467328e-01,   9.74324559e-01,   9.99328632e-01,
         2.91312374e-12,   1.00998256e-01,   9.86992421e-01,
         9.97149193e-01,   9.13815924e-01,   9.98807818e-01,
         9.84005486e-01,   3.17865443e-08,   2.30937811e-11,
         9.98036358e-01,   9.99532884e-01,   1.24075526e-03,
         9.98819765e-01,   9.99752279e-01,   8.53677349e-04,
         1.53192255e-01,   9.30832406e-01,   1.49723823e-05,
         5.28688983e-01,   1.48786146e-03,   9.92804571e-51,
         8.86447353e-01,   9.95516043e-01,   9.98554149e-01,
         1.75078944e-03,   9.99922978e-01,   4.67159833e-01,
         9.99825913e-01,   9.57716419e-01,   9.95069689e-01,
         9.98728887e-01,   7.49375338e-14,   9.92513330e-01,
         1.49918676e-02,   1.63977226e-02,   9.95785292e-01,
         9.56124754e-01,   3.53639065e-01,   9.96011137e-01,
         7.27728677e-33,   9.97779030e-01,   7.77872222e-02,
         9.90058068e-01,   9.80367925e-01,   2.92408222e-01,
         9.98164180e-01,   1.67926421e-01,   9.99996297e-01,
         6.35631576e-10,   1.06440027e-01])</pre>
</div>

</div>

</div>
</div>

</div>
    </div>
  </div>

    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/optimising-hyper-parameters-efficiently-with-scikit-optimize/" class="u-url">Optimising hyper-parameters efficiently with Scikit-Optimize</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Blair Hudson
            </span></p>
            <p class="dateline"><a href="posts/optimising-hyper-parameters-efficiently-with-scikit-optimize/" rel="bookmark"><time class="published dt-published" datetime="2017-09-16T15:59:59+10:00" title="2017-09-16 15:59">2017-09-16 15:59</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>One of the most well-known techniques for experimenting with various model configurations is <em>Grid Search</em>.</p>
<p>With grid search, you specify a discrete search space (a parameter grid) of all of the parameter values you would like to test. The search permutes through the grid, testing various combinations until all are exhausted. Basic a specified performance metric (e.g. error), you can select the best parameter combination for your model.</p>
<p>What's wrong with this?</p>
<p>If you have a large parameter grid, this doesn't work too well:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'param_a'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
    <span class="s1">'param_b'</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
    <span class="s1">'param_c'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">num_searches</span><span class="p">(</span><span class="n">param_grid</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">param_grid</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
    
<span class="n">num_searches</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[1]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>27</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And maybe we want to search over four possible values instead for <code>param_a</code>, and add two more new parameters:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'param_a'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span>
    <span class="s1">'param_b'</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
    <span class="s1">'param_c'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
    <span class="s1">'param_d'</span><span class="p">:</span> <span class="p">[</span><span class="s2">"a"</span><span class="p">,</span> <span class="s2">"b"</span><span class="p">],</span>
    <span class="s1">'param_e'</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">num_searches</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[2]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>216</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see from the first grid, there's already 27 combinations to try. Then this jumps to 216 for our larger grid. Depending on the complexity of the model and the amount of data to process, this can very easily become infeasible.</p>
<p>There are a few approaches to solving this, including:</p>
<ul>
<li>breaking down the search into multiple smaller steps (such as searching <code>param_a</code> and <code>param_b</code> first, with defaults for the others, then using the best values to search the remaining parameters - this can be tricky in practice)</li>
<li>searching the parameter space <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html">at random</a> (which has an additional benefit of discovering better parameter values when random samples are drawn frmo a continuous range)</li>
</ul>
<p>While Scikit-Learn doesn't provide many more options, some <a href="https://github.com/scikit-optimize/scikit-optimize/blob/master/AUTHORS.md">clever people</a> have developed a drop-in replacement for Scikit-Learn's <code>GridSearchCV</code> and <code>RandomizedSearchCV</code> called <code>BayesSearchCV</code> in a package called <em>Scikit-Optimize</em>.</p>
<p>Let's install Scikit-Optimize and implement <code>BayesSearchCV</code> with a simple example!</p>
<h3 id="Installing-Scikit-Optimize">Installing Scikit-Optimize<a class="anchor-link" href="posts/optimising-hyper-parameters-efficiently-with-scikit-optimize/#Installing-Scikit-Optimize">¶</a>
</h3>
<p>Assuming you already have already <a href="posts/using-jupyter-notebooks-with-anaconda/">installed Anaconda and Jupyter</a>, you will need to do the following:</p>
<ul>
<li><code>pip install scikit-optimize</code></li>
</ul>
<p>If you have trouble installing, you may first need to run the following to install one of Scikit-Optmize's dependencies:</p>
<ul>
<li><code>pip install scikit-garden</code></li>
</ul>
<h3 id="Implementing-BayesSearchCV">Implementing BayesSearchCV<a class="anchor-link" href="posts/optimising-hyper-parameters-efficiently-with-scikit-optimize/#Implementing-BayesSearchCV">¶</a>
</h3>
<p>Here's an example implementation using a sample dataset and <a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">Logistic Regression</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">'ignore'</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">skopt</span> <span class="k">import</span> <span class="n">BayesSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="k">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>

<span class="c1"># prep some sample data</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">)</span>

<span class="c1"># we're using a logistic regression model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># this is our parameter grid</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'solver'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'liblinear'</span><span class="p">,</span> <span class="s1">'saga'</span><span class="p">],</span>  
    <span class="s1">'penalty'</span><span class="p">:</span> <span class="p">[</span><span class="s1">'l1'</span><span class="p">,</span><span class="s1">'l2'</span><span class="p">],</span>
    <span class="s1">'tol'</span><span class="p">:</span> <span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="s1">'log-uniform'</span><span class="p">),</span>
    <span class="s1">'C'</span><span class="p">:</span> <span class="p">(</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="s1">'log-uniform'</span><span class="p">),</span>
    <span class="s1">'fit_intercept'</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># set up our optimiser to find the best params in 30 searches</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">BayesSearchCV</span><span class="p">(</span>
    <span class="n">clf</span><span class="p">,</span>
    <span class="n">param_grid</span><span class="p">,</span>
    <span class="n">n_iter</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">1234</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="n">opt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Best params achieve a test score of'</span><span class="p">,</span> <span class="n">opt</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="s1">':'</span><span class="p">)</span>

<span class="n">opt</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>

<div class="output_subarea output_stream output_stdout output_text">
<pre>Best params achieve a test score of 0.958041958042 :
</pre>
</div>
</div>

<div class="output_area">
<div class="prompt output_prompt">Out[4]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>{'C': 100.0,
 'fit_intercept': True,
 'penalty': 'l1',
 'solver': 'liblinear',
 'tol': 0.00094035472283658726}</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By increasing the value of <code>n_iter</code>, you can continue the search to find better parameter combinations. You can also use the optimiser for prediction, by calling <code>.predict()</code> or <code>.predict_proba()</code> for probabilities, or extract and use the best one standalone:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">opt</span><span class="o">.</span><span class="n">best_estimator_</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[5]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=1234, solver='liblinear',
          tol=0.00094035472283658726, verbose=0, warm_start=False)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You may also find it useful to re-use the best parameters programatically to define an equivalent model:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">LogisticRegression</span><span class="p">(</span><span class="o">**</span><span class="n">opt</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt output_prompt">Out[6]:</div>



<div class="output_text output_subarea output_execute_result">
<pre>LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l1', random_state=None, solver='liblinear',
          tol=0.00094035472283658726, verbose=0, warm_start=False)</pre>
</div>

</div>

</div>
</div>

</div>
    </div>
  </div>

    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/creating-a-blog-with-jupyter-notebooks/" class="u-url">Creating a blog with Jupyter notebooks</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Blair Hudson
            </span></p>
            <p class="dateline"><a href="posts/creating-a-blog-with-jupyter-notebooks/" rel="bookmark"><time class="published dt-published" datetime="2017-09-13T21:29:29+10:00" title="2017-09-13 21:29">2017-09-13 21:29</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Assuming you already have already <a href="posts/using-jupyter-notebooks-with-anaconda/">installed Jupyter notebook</a>, you will need to do the following:</p>
<h3 id="Installing-and-configuring-a-Nikola-blog">Installing and configuring a Nikola blog<a class="anchor-link" href="posts/creating-a-blog-with-jupyter-notebooks/#Installing-and-configuring-a-Nikola-blog">¶</a>
</h3>
<ol>
<li>
<p>First you'll need to create a directory structure as follows:</p>

<pre><code> - /blog
 -- /posts
 -- /output</code></pre>
<ul>
<li>
<code>/blog</code> is the root directory for everything you'll be doing with your blog</li>
<li>
<code>/posts</code> is where you'll store your Jupyter notebooks</li>
<li>
<code>/output</code> will contain the code generated for your blog</li>
</ul>
</li>
<li>
<p>Run the following command to install Nikola (the static website generator which will do most of the heavy lifting)<sup>[1]</sup>:</p>
<p><code>pip install --upgrade "Nikola[extras]"</code></p>
</li>
<li>
<p>Change directory to your blog root:</p>
<p><code>cd blog</code></p>
</li>
<li>
<p>Start up Nikola, following the prompts to configure your new blog:</p>
<p><code>nikola init .</code></p>
</li>
<li>
<p>Open <code>/blog/conf.py</code> and change the <code>POSTS</code> and <code>PAGES</code> sections to include the lines as follows. This will allow Nikola to treat <code>.ipynb</code> files as blog posts.</p>

<pre><code> POSTS = (
     ("posts/*.rst", "posts", "post.tmpl"),
     ("posts/*.md", "posts", "post.tmpl"),
     ("posts/*.txt", "posts", "post.tmpl"),
     ("posts/*.html", "posts", "post.tmpl"),
     ("posts/*.ipynb", "posts", "post.tmpl"),
 )
 PAGES = (
     ("pages/*.rst", "pages", "page.tmpl"),
     ("pages/*.md", "pages", "page.tmpl"),
     ("pages/*.txt", "pages", "page.tmpl"),
     ("pages/*.html", "pages", "page.tmpl"),
     ("pages/*.ipynb", "pages", "page.tmpl"),
 )</code></pre>
</li>
<li>
<p>Write your blog post in Jupyter, saving the <code>.ipynb</code> file to <code>/posts</code>.</p>
</li>
<li>
<p>You will need to explicitly add the following metadata to your notebook (in the Jupyter menu, select <em>Edit &gt; Edit Notebook Metadata</em>). Change the metadata to match your post.<sup>[2]</sup></p>

<pre><code> "nikola": {
     "title": "Creating a blog with Jupyter notebooks",
     "slug": "creating-a-blog-with-jupyter-notebooks",
     "date": "2017-09-09 21:09:01 UTC+10:00"
 }</code></pre>
</li>
<li>
<p>Run <code>nikola build</code> each time you update your <code>/posts</code>, which will generate your site and store it in <code>/output</code>!</p>
</li>
<li>
<p>If you're going to be publishing your blog on Github (like me), you can push the content of <code>/output</code> to your website repo (<a href="https://github.com/blairhudson/blog">example</a>).</p>
</li>
</ol>
<h4 id="[1]Problems-installing-Nikola?">
<sup>[1]</sup>Problems installing Nikola?<a class="anchor-link" href="posts/creating-a-blog-with-jupyter-notebooks/#%5B1%5DProblems-installing-Nikola?">¶</a>
</h4>
<p>I ran into some issues installing Nikola on OS X with Anaconda. Specifically, <code>gcc</code> in Anaconda was the culprit. Resolution:</p>
<ul>
<li>
<code>conda remove gcc</code> to uninstall <code>gcc</code> provided by Anaconda</li>
</ul>
<p>This will default to the system <code>gcc</code>, which you can check by running <code>which gcc</code> (which should output <code>/usr/bin/gcc</code>).</p>
<p>If this still doesn't resolve the issue still, you may need to install a more up-to-date <code>gcc</code>:</p>
<ol>
<li>Install <a href="https://brew.sh">Homebrew</a>
</li>
<li>
<code>brew install gcc</code> (you may be prompted to install Developer Tools)</li>
<li><code>brew unlink gcc</code></li>
<li><code>brew link --overwrite gcc</code></li>
</ol>
<p><code>which gcc</code> should now show <code>/usr/local/Cellar/gcc/7.2.0</code>. 👍</p>
<h4 id="[2]Inferring-Nikola-post-metadata">
<sup>[2]</sup>Inferring Nikola post metadata<a class="anchor-link" href="posts/creating-a-blog-with-jupyter-notebooks/#%5B2%5DInferring-Nikola-post-metadata">¶</a>
</h4>
<p>Like me, you probably want as little as possible to come between your latest notebook hack and your awesome new blog.</p>
<p>Nikola parses Jupyter notebooks with a plugin, which with some modification we can have infer all of the Nikola post metadata automatically. For me, the plugin file was here (though it may differ for you):</p>
<p><code>~/anaconda/lib/python3.5/site-packages/nikola/plugins/compile/ipynb.py</code></p>
<p>To automagically infer the required metadata, you can replace the <code>read_metadata()</code> function in the file above with the following code:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">read_metadata</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">post</span><span class="p">,</span> <span class="n">file_metadata_regexp</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">unslugify_titles</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">"""Read metadata directly from ipynb file.</span>

<span class="sd">    As ipynb file support arbitrary metadata as json, the metadata used by Nikola</span>
<span class="sd">    will be assume to be in the 'nikola' subfield.</span>
<span class="sd">    """</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_req_missing_ipynb</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">lang</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">lang</span> <span class="o">=</span> <span class="n">LocaleBorg</span><span class="p">()</span><span class="o">.</span><span class="n">current_lang</span>
    <span class="n">source</span> <span class="o">=</span> <span class="n">post</span><span class="o">.</span><span class="n">translated_source_path</span><span class="p">(</span><span class="n">lang</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">"utf8"</span><span class="p">)</span> <span class="k">as</span> <span class="n">in_file</span><span class="p">:</span>
        <span class="n">nb_json</span> <span class="o">=</span> <span class="n">nbformat</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">in_file</span><span class="p">,</span> <span class="n">current_nbformat</span><span class="p">)</span>
    <span class="c1"># Metadata might not exist in two-file posts or in hand-crafted</span>
    <span class="c1"># .ipynb files.</span>

    <span class="c1"># infer metadata</span>
    <span class="n">title</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">source</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">slug</span> <span class="o">=</span> <span class="n">title</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">' '</span><span class="p">,</span> <span class="s1">'-'</span><span class="p">)</span>
    <span class="kn">from</span> <span class="nn">datetime</span> <span class="k">import</span> <span class="n">datetime</span>
    <span class="n">date</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">fromtimestamp</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getctime</span><span class="p">(</span><span class="n">source</span><span class="p">))</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">'%Y-%m-</span><span class="si">%d</span><span class="s1"> %k:%M:%S'</span><span class="p">)</span>

    <span class="n">implicit</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'title'</span><span class="p">:</span><span class="n">title</span><span class="p">,</span> <span class="s1">'slug'</span><span class="p">:</span> <span class="n">slug</span><span class="p">,</span> <span class="s1">'date'</span><span class="p">:</span><span class="n">date</span><span class="p">}</span>
    <span class="n">explicit</span> <span class="o">=</span> <span class="n">nb_json</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'metadata'</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'nikola'</span><span class="p">,</span> <span class="p">{})</span>
    
    <span class="c1"># replace inference with explicit if available</span>
    <span class="n">metadata</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">implicit</span><span class="p">,</span> <span class="o">**</span><span class="n">explicit</span><span class="p">}</span>

    <span class="k">return</span> <span class="n">metadata</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With this small modification, we instruct Nikola to infer the <code>title</code> and <code>slug</code> values based on the filename, and the <code>date</code> value based on the filesystem. Magical! ✨</p>
<p><strong>Update:</strong> The makers of Nikola have suggested some official methods for achieving this that are built right into the existing workflow:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">html</span>
&lt;blockquote class="twitter-tweet" data-conversation="none" data-lang="en"&gt;&lt;p lang="en" dir="ltr"&gt;Titles and slugs can be done via FILE_METADATA_REGEXP, and auto dates are prone to issues.&lt;br&gt;Better: import files with `nikola new_post -i`&lt;/p&gt;&amp;mdash; Nikola Generator (@GetNikola) &lt;a href="https://twitter.com/GetNikola/status/907570254611484672"&gt;September 12, 2017&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8"&gt;&lt;/script&gt;
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">
<div class="prompt"></div>


<div class="output_html rendered_html output_subarea ">
<blockquote class="twitter-tweet" data-conversation="none" data-lang="en">
<p lang="en" dir="ltr">Titles and slugs can be done via FILE_METADATA_REGEXP, and auto dates are prone to issues.<br>Better: import files with `nikola new_post -i`</p>— Nikola Generator (@GetNikola) <a href="https://twitter.com/GetNikola/status/907570254611484672">September 12, 2017</a>
</blockquote> <script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>

</div>

</div>
</div>

</div>
    </div>
  </div>

    </div>
    </article>
</div>





        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha256-SDRP1VVYu+tgAGKhddBSl5+ezofHKZeI+OzxakbIe/Y=" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']]}});
        </script><!--End of body content--><footer id="footer">
            Contents © 2017         <a href="http://blairhudson.com">Blair Hudson</a>
            
        </footer>
</div>
</div>


            <script src="assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-99092313-1', 'auto');
    ga('send', 'pageview');
</script>
</body>
</html>
